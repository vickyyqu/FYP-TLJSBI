{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "clientID = 'TTHvGhN8VYCNdie1uB83vg'\n",
    "clientSecret = '6FCjvM6iIrthyu7DkM7k__z95sra-g'\n",
    "\n",
    "import praw\n",
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import re\n",
    "import math\n",
    "import os\n",
    "\n",
    "reddit = praw.Reddit(\n",
    "    client_id= clientID,\n",
    "    client_secret= clientSecret,\n",
    "    user_agent='reg',\n",
    "\n",
    ")\n",
    "\n",
    "subreddit = reddit.subreddit('appliances')\n",
    "\n",
    "def get_submission_info(submission):\n",
    "    title = submission.title\n",
    "    content = submission.selftext\n",
    "    comments = [comment.body.replace('\\n', ' ') for comment in sorted(submission.comments, key=lambda x: x.score, reverse=True)[:30] if isinstance(comment, praw.models.Comment)]\n",
    "    kudos = submission.score\n",
    "    upvotes = submission.ups\n",
    "    submission_date = submission.created_utc\n",
    "\n",
    "    content = content.replace('\\n', ' ')\n",
    "    comments_dates = [comment.created_utc for comment in sorted(submission.comments, key=lambda x: x.score, reverse=True)[:30] if isinstance(comment, praw.models.Comment)]\n",
    "\n",
    "    return {\n",
    "        'Title': title,\n",
    "        'Content': content,\n",
    "        'Top_Comments': comments,\n",
    "        'Kudos': kudos,\n",
    "        'Upvotes': upvotes,\n",
    "        'Submission_Date': submission_date,\n",
    "        'Comments_Dates': comments_dates\n",
    "    }\n",
    "\n",
    "# subreddit.hot(limit=100)\n",
    "submission_info_list = []\n",
    "\n",
    "# Make multiple requests until you accumulate 700 submissions\n",
    "count = 0\n",
    "while count < 500:\n",
    "    # Retrieve submissions with a limit of 100 per request\n",
    "    for submission in subreddit.search(\"best\", limit=100):\n",
    "        submission_info = get_submission_info(submission)\n",
    "        submission_info_list.append(submission_info)\n",
    "        count += 1\n",
    "        if count >= 700:\n",
    "            break  # Exit the loop if we have enough submissions\n",
    "\n",
    "df = pd.DataFrame(submission_info_list)\n",
    "\n",
    "def column_to_list(csv_file, column_index):\n",
    "    df = pd.read_csv(csv_file, skiprows=1)\n",
    "    column_list = df.iloc[:, column_index].tolist()\n",
    "\n",
    "    column_list.remove(\"GOOGLE\")\n",
    "    \n",
    "    return column_list\n",
    "\n",
    "# need to add to s3 and get the csv file\n",
    "csv_file = \"cleaned_brands.csv\" \n",
    "column_index = 1 \n",
    "unique_brands = column_to_list(csv_file, column_index)\n",
    "\n",
    "unique_categories = [\n",
    "    \"Air Conditioner\",\n",
    "    \"Air Fryer\",\n",
    "    \"Air Purifier\",\n",
    "    \"Bread Maker\",\n",
    "    \"Blender\",\n",
    "    \"Clothes Steamer\",\n",
    "    \"Coffee Machine\",\n",
    "    \"Cooktop\",\n",
    "    \"Dishwasher\",\n",
    "    \"Dryer\",\n",
    "    \"Electric Kettle\",\n",
    "    \"Espresso Machine\",\n",
    "    \"Fan\",\n",
    "    \"Food Processor\",\n",
    "    \"Griddle\",\n",
    "    \"Grill\",\n",
    "    \"Hand Mixer\",\n",
    "    \"Heater\",\n",
    "    \"Humidifier\",\n",
    "    \"Ice Cream Maker\",\n",
    "    \"Iron\",\n",
    "    \"Juicer\",\n",
    "    \"Microwave\",\n",
    "    \"Oven\",\n",
    "    \"Range Hood\",\n",
    "    \"Refrigerator\",\n",
    "    \"Rice Cooker\",\n",
    "    \"Robot Vacuum\",\n",
    "    \"Slow Cooker\",\n",
    "    \"Smart Doorbell\",\n",
    "    \"Smart Lighting\",\n",
    "    \"Smart Lock\",\n",
    "    \"Smart Thermostat\",\n",
    "    \"Sound System\",\n",
    "    \"Stand Mixer\",\n",
    "    \"Television\",\n",
    "    \"Toaster\",\n",
    "    \"Vacuum Cleaner\",\n",
    "    \"Waffle Maker\",\n",
    "    \"Washing Machine\",\n",
    "    \"Water Heater\",\n",
    "    \"Water Purifier\",\n",
    "    \"Washer\"\n",
    "]\n",
    "\n",
    "############################ Sentiment analysis section ############################\n",
    "\n",
    "# Initialize BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)  # Positive, neutral and negative sentiments\n",
    "\n",
    "## Purpose: Get sentiment analysis\n",
    "def get_senti_analysis(sentiment_collection, sentence, brand_cat, max_length=512):\n",
    "    brand = brand_cat[0]\n",
    "\n",
    "    # Tokenize and truncate the sentence\n",
    "    modified_sentence = sentence.lower() \n",
    "    tokenized_sentence = tokenizer.encode(modified_sentence, add_special_tokens=True, max_length=max_length, truncation=True)\n",
    "\n",
    "    # Find indices of brand mentions in the tokenized sentence\n",
    "    brand_indices = [i for i, token in enumerate(tokenized_sentence) if tokenizer.decode([token]) == brand.lower()]\n",
    "\n",
    "    # Modify the sentence to focus on the specified brand\n",
    "    for idx in brand_indices:\n",
    "        tokenized_sentence[idx] = tokenizer.convert_tokens_to_ids(\"[MASK]\")  # Replace brand mentions with [MASK] token\n",
    "\n",
    "    # Convert tokenized sentence to PyTorch tensor\n",
    "    input_ids = torch.tensor([tokenized_sentence])\n",
    "    sentiment = ''\n",
    "\n",
    "    # Perform sentiment analysis\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "        logits = outputs.logits\n",
    "        predicted_labels = torch.argmax(logits, dim=1).tolist()\n",
    "\n",
    "        if predicted_labels[0] == 1:\n",
    "            sentiment = \"positive\"\n",
    "        elif predicted_labels[0] == 0:\n",
    "            sentiment = \"neutral\"\n",
    "        elif predicted_labels[0] == 2:\n",
    "            sentiment = \"negative\"\n",
    "\n",
    "    sentiment_collection[brand_cat][sentiment] += 1\n",
    "\n",
    "    return sentiment_collection\n",
    "\n",
    "\n",
    "## Purpose: To get the brand and category of the sentence, then add to the sentiment collection\n",
    "## Depends on the get_senti_analysis function\n",
    "def get_brand_and_category(sentiment_collection, brands, sentences, categories):\n",
    "    for brand in brands:\n",
    "        # Tokenize the sentence using regular expressions\n",
    "        sentence_words = re.findall(r'\\b\\w+\\b', sentences.lower())\n",
    "\n",
    "        if brand.lower() in sentence_words:\n",
    "            cat = \"\"\n",
    "\n",
    "            for category in categories:\n",
    "                if category.lower() in sentence_words:\n",
    "                    cat = category\n",
    "                    if cat == \"Washer\":\n",
    "                        cat = \"Washing Machine\"\n",
    "\n",
    "            brand = brand.replace(\" \", \"\").lower()\n",
    "            brand_cat = (brand, cat)\n",
    "            \n",
    "            if brand_cat not in sentiment_collection:\n",
    "                sentiment_collection[brand_cat] = {\"positive\": 0, \"negative\": 0, \"neutral\": 0}\n",
    "            \n",
    "            sentiment_collection = get_senti_analysis(sentiment_collection, sentences, brand_cat)\n",
    "\n",
    "    return sentiment_collection\n",
    "\n",
    "sentiment_collection = {}\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    if row['Top_Comments'] != []:\n",
    "        for comments in row['Top_Comments']:\n",
    "            get_brand_and_category(sentiment_collection, unique_brands, comments, unique_categories)\n",
    "\n",
    "    if row['Content'] != \"\":\n",
    "        get_brand_and_category(sentiment_collection, unique_brands, row['Content'], unique_categories)\n",
    "    \n",
    "    if row['Title'] != \"\":\n",
    "        get_brand_and_category(sentiment_collection, unique_brands, row['Title'], unique_categories)\n",
    "\n",
    "\n",
    "## Purpose: To combine the sentiment scores of the same brand to have a general understanding of which brands are more popular\n",
    "combined_sentiment_collection = {}\n",
    "brands_with_categories = set()\n",
    "for key in sentiment_collection.keys():\n",
    "    brand, category = key\n",
    "    if category != '':\n",
    "        brands_with_categories.add(brand)\n",
    "\n",
    "for brand, category in sentiment_collection.keys():\n",
    "    for key in sentiment_collection.keys():\n",
    "        if key[0] == brand:\n",
    "            for sentiment in sentiment_collection[key]:\n",
    "                if (brand, '') not in combined_sentiment_collection:\n",
    "                    combined_sentiment_collection[(brand, '')] = {}\n",
    "                combined_sentiment_collection[(brand, '')][sentiment] = combined_sentiment_collection[(brand, '')].get(sentiment, 0) + sentiment_collection[key][sentiment]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalizing popularity scores\n",
    "def min_max_scaling(scores):\n",
    "    print(scores)\n",
    "    values = scores.values()\n",
    "    min_score = min(values)\n",
    "    max_score = max(values)\n",
    "    if min_score == max_score:\n",
    "        # Handle the case where all values are the same\n",
    "        return {brand: 0.5 for brand in scores}  # Assigning 0.5 as a default scaled value\n",
    "\n",
    "    scaled_scores = {brand: (score - min_score) / (max_score - min_score) for brand, score in scores.items()}\n",
    "    return scaled_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Getting populatiry scores\n",
    "def get_popular_score(sentiment_dictionary, type_check):\n",
    "    total_sentiments = {brand: sum(sentiments.values()) for brand, sentiments in sentiment_dictionary.items()}\n",
    "\n",
    "    # Calculate normalized sentiment scores and popularity score for each brand\n",
    "    popularity_scores = {}\n",
    "    for brand, sentiments in sentiment_dictionary.items():\n",
    "        total = total_sentiments[brand]\n",
    "        positive_score = sentiments['positive'] / total if total > 0 else 0\n",
    "        negative_score = sentiments['negative'] / total if total > 0 else 0\n",
    "        neutral_score = sentiments['neutral'] / total if total > 0 else 0\n",
    "        \n",
    "        # Penalize brands with fewer counts using logarithmic scaling\n",
    "        penalization_factor = math.log10(total + 1)  # Adding 1 to prevent division by zero\n",
    "        popularity_score = ((positive_score * 0.65) + (neutral_score * 0.15) - (negative_score * 0.2)) * penalization_factor\n",
    "        if type_check == \"general\":\n",
    "            popularity_scores[brand[0]] = popularity_score\n",
    "        else:\n",
    "            popularity_scores[brand] = popularity_score\n",
    "\n",
    "    # Sort brands by popularity score\n",
    "    sorted_brands = sorted(popularity_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    return popularity_scores\n",
    "\n",
    "# Getting hardware zone data\n",
    "json_file_hardware = './output/23Mar_Tester.json'\n",
    "\n",
    "def get_brand_and_category_noSentiment(title, desc, categories, brands):\n",
    "    brand_cat = \"\"\n",
    "    for brand in brands:\n",
    "        # Tokenize the sentence using regular expressions\n",
    "        title_words = re.findall(r'\\b\\w+\\b', title.lower())\n",
    "        description_words = re.findall(r'\\b\\w+\\b', desc.lower())\n",
    "\n",
    "        if brand.lower() in title_words or brand.lower() in description_words:\n",
    "            cat = \"\"\n",
    "\n",
    "            for category in categories:\n",
    "                if category.lower() in title_words or category.lower() in description_words:\n",
    "                    cat = category\n",
    "                    if cat == \"Washer\":\n",
    "                        cat = \"Washing Machine\"\n",
    "\n",
    "            ##### MIGHT BE ERRONEOUS #####\n",
    "            brand = brand.replace(\" \", \"\").lower()\n",
    "            brand_cat = [brand, cat]\n",
    "\n",
    "    return brand_cat\n",
    "\n",
    "hardware_df = pd.read_json(json_file_hardware)\n",
    "df_hardware = hardware_df.drop(columns=['error'])\n",
    "df_hardware.dropna(inplace=True)\n",
    "df_hardware = df_hardware.reset_index(drop=True)\n",
    "\n",
    "hardware_brandCat = []\n",
    "brand_cat = \"\"\n",
    "for idx, row in df_hardware.iterrows():\n",
    "    brand_cat = get_brand_and_category_noSentiment(row['title'], row['description'], unique_categories, unique_brands)\n",
    "\n",
    "    if brand_cat not in hardware_brandCat and brand_cat != '':\n",
    "        hardware_brandCat.append(brand_cat)\n",
    "\n",
    "## Purpose: To create a dictionary of brand sentiments based on their category\n",
    "df_legend = {}\n",
    "found_categories = set()\n",
    "for brand_cat, sentiments in sentiment_collection.items():\n",
    "    brand, category = brand_cat\n",
    "    \n",
    "    if category == \"\":\n",
    "        continue\n",
    "\n",
    "    df_name = \"df_\" + category\n",
    "    found_categories.add(category)\n",
    "    \n",
    "    if df_name not in df_legend:\n",
    "        df_legend[df_name] = {}\n",
    "    \n",
    "    if brand not in df_legend[df_name]:\n",
    "        df_legend[df_name][brand] = {\"positive\": sentiments[\"positive\"], \"neutral\": sentiments[\"neutral\"], \"negative\": sentiments[\"negative\"]}\n",
    "    else:\n",
    "        # If brand already exists, sum up sentiments\n",
    "        df_legend[df_name][brand][\"positive\"] += sentiments[\"positive\"]\n",
    "        df_legend[df_name][brand][\"neutral\"] += sentiments[\"neutral\"]\n",
    "        df_legend[df_name][brand][\"negative\"] += sentiments[\"negative\"]\n",
    "\n",
    "dfs = {}\n",
    "\n",
    "# Iterate over the dictionary\n",
    "for key, value in df_legend.items():\n",
    "    \n",
    "    final_df = pd.DataFrame(value).transpose()\n",
    "    dfs[key] = final_df\n",
    "\n",
    "## Purpose: To get the popularity scores of the brands in each category and scale them\n",
    "pop_col_list = []\n",
    "for df_name, internal_df in df_legend.items():\n",
    "    pop_col = get_popular_score(internal_df, \"category\")\n",
    "    df_category = df_name[3:]\n",
    "\n",
    "    pop_col_list.append([pop_col, df_category])\n",
    "\n",
    "## Adding in advertisement data from hardware zone\n",
    "for column, category in pop_col_list:\n",
    "    for brand, cat in hardware_brandCat:\n",
    "        if cat == category:\n",
    "            column[brand] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'GE': -0.05122710528293813, 'MIELE': 0.9884171554996024, 'LG': 0.9237543509342077, 'BOSCH': 0.04346097776309703, 'WHIRLPOOL': 0.8331539230050247, 'SAMSUNG': 0.44151066030717245}\n",
      "{'GE': 0.39669821758265894, 'LG': 1.2166115334138488, 'WHIRLPOOL': 1.1099206144636586, 'MIELE': 0.7892676968176956, 'SAMSUNG': 0.4446578573620821, 'ELECTROLUX': 0.6338287198795659, 'BOSCH': -0.20322595720552575, 'SMEG': 0.11672268755754654, 'MITSUBISHI': 0.15620890277373375, 'TOWER': -0.15563025007672873}\n",
      "{'SMEG': 0.6769052453528464, 'BERTAZZONI': 0.6769052453528464, 'BOSCH': 0.4131935296043498, 'ELECTROLUX': 0.5819913249503637, 'GE': 0.13222192947339192, 'LG': 0.41655707406329007, 'SAMSUNG': -0.24082399653118497, 'MIELE': 0.41655707406329007, 'TURBO': 0.11672268755754654}\n",
      "{'GE': -0.15563025007672873, 'BOSCH': -0.15563025007672873}\n",
      "{'LG': 1.0115966254987367, 'GE': 0.05659893391883273, 'SAMSUNG': 0.33555638111271135, 'BOSCH': 0.01652774118417397, 'WHIRLPOOL': 0.9197326761810317}\n",
      "{'WHIRLPOOL': 0.6769052453528464, 'GE': -0.15563025007672873, 'SAMSUNG': -0.15563025007672873, 'TOSHIBA': 0.5057983127493684, 'LG': 0.6769052453528464, 'MIELE': 0.5057983127493684, 'BOSCH': -0.15563025007672873}\n",
      "{'BOSCH': -0.15563025007672873, 'SAMSUNG': 1}\n",
      "{'LG': 0.5057983127493684}\n",
      "{'LG': 0.5057983127493684, 'GE': -0.15563025007672873, 'BOSCH': -0.20827853703164503}\n",
      "{'PANASONIC': 0.5057983127493684, 'BOSCH': 0.5057983127493684}\n"
     ]
    }
   ],
   "source": [
    "## Scaling the popularity scores        \n",
    "scaled_pop_col_list = []\n",
    "for pop_list in pop_col_list:\n",
    "    scaled_scores = min_max_scaling(pop_list[0])\n",
    "    scaled_pop_col_list.append(scaled_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'df_Dishwasher':            positive  neutral  negative  popularity\n",
       " GE               10        0        40    0.000000\n",
       " MIELE            40        5         0    1.000000\n",
       " LG               40        0         5    0.937803\n",
       " BOSCH            35        0       100    0.091077\n",
       " WHIRLPOOL        45        5        10    0.850657\n",
       " SAMSUNG          10        0         5    0.473948,\n",
       " 'df_Washing Machine':             positive  neutral  negative  popularity\n",
       " GE                30       10        30    0.422530\n",
       " LG               120       15         5    1.000000\n",
       " WHIRLPOOL         50        0         0    0.924857\n",
       " MIELE             25       10         0    0.699019\n",
       " SAMSUNG           20        0        15    0.456308\n",
       " ELECTROLUX        20        5         5    0.589543\n",
       " BOSCH              0       10        35    0.000000\n",
       " SMEG               0        5         0    0.225342\n",
       " MITSUBISHI         0       10         0    0.253152\n",
       " TOWER              0        0         5    0.033522,\n",
       " 'df_Oven':             positive  neutral  negative  popularity\n",
       " SMEG              10        0         0    1.000000\n",
       " BERTAZZONI        10        0         0    1.000000\n",
       " BOSCH             10        5         5    0.712648\n",
       " ELECTROLUX        10        5         0    0.896577\n",
       " GE                 5        5        10    0.406488\n",
       " LG                 5        5         0    0.716313\n",
       " SAMSUNG            0        0        15    0.000000\n",
       " MIELE              5        5         0    0.716313\n",
       " TURBO              0        5         0    0.389599,\n",
       " 'df_Cooktop':        positive  neutral  negative  popularity\n",
       " GE            0        0         5         0.5\n",
       " BOSCH         0        0         5         0.5,\n",
       " 'df_Refrigerator':            positive  neutral  negative  popularity\n",
       " LG               35        0         0    1.000000\n",
       " GE                5        5        15    0.040270\n",
       " SAMSUNG          15        0        15    0.320610\n",
       " BOSCH             5        0        15    0.000000\n",
       " WHIRLPOOL        25        0         0    0.907681,\n",
       " 'df_Dryer':            positive  neutral  negative  popularity\n",
       " WHIRLPOOL        10        0         0    1.000000\n",
       " GE                0        0         5    0.000000\n",
       " SAMSUNG           0        0         5    0.000000\n",
       " TOSHIBA           5        0         0    0.794475\n",
       " LG               10        0         0    1.000000\n",
       " MIELE             5        0         0    0.794475\n",
       " BOSCH             0        0         5    0.000000,\n",
       " 'df_Fan':        negative  neutral  positive\n",
       " BOSCH         5        0         0,\n",
       " 'df_Griddle':     negative  neutral  positive\n",
       " LG         0        0         5,\n",
       " 'df_Heater':        positive  neutral  negative\n",
       " LG            5        0         0\n",
       " GE            0        0         5\n",
       " BOSCH         0        0        10,\n",
       " 'df_Microwave':            positive  neutral  negative\n",
       " PANASONIC         5        0         0\n",
       " BOSCH             5        0         0}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WHIRLPOOL': 1.8172361654640476, 'BOSCH': -0.3976073486376901, 'GE': -0.12088028476270986, 'MIELE': 1.355731175637765, 'LG': 2.0484853030134076, 'SAMSUNG': 0.06244099385489667, 'SMEG': 0.8463661165263562, 'BERTAZZONI': 1.048309506867828, 'ELECTROLUX': 1.0730441092090033, 'SHARP': 0.10034333188799374, 'MIDEA': 0.6769052453528464, 'TOWER': -0.29827233876685455, 'PANASONIC': 0.5057983127493684, 'TOSHIBA': 0.8594425415770476, 'MITSUBISHI': 0.15620890277373375, 'PHILIPS': -0.15563025007672873, 'HISENSE': 0.44151066030717245, 'TURBO': 0.11672268755754654, 'TIGER': -0.15563025007672873}\n"
     ]
    }
   ],
   "source": [
    "## Purpose: To add the popularity scores to the dataframes\n",
    "for i in range(len(scaled_pop_col_list)):\n",
    "    target_df = dfs[list(dfs.keys())[i]]\n",
    "    target_df['popularity'] = pd.Series(scaled_pop_col_list[i], index=target_df.index)\n",
    "\n",
    "############################ JSON output section ############################\n",
    "\n",
    "output_directory = \"./output/\"\n",
    "\n",
    "# Make sure the directory exists to save the JSON files\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "### Ouptut for json file on general popularity of brands\n",
    "popular_brands = get_popular_score(combined_sentiment_collection, \"general\")\n",
    "scaled_scores = min_max_scaling(popular_brands)\n",
    "\n",
    "# Convert to JSON\n",
    "json_data = json.dumps(dict(scaled_scores), indent=4)\n",
    "outputLine = output_directory + \"general_popular_brands.json\"\n",
    "\n",
    "# Write JSON data to a file\n",
    "with open(outputLine, 'w') as json_file:\n",
    "    json_file.write(json_data)\n",
    "\n",
    "\n",
    "# Iterate over the dataframes in the dfs dictionary\n",
    "for df_name, final_df in dfs.items():\n",
    "    # Convert DataFrame to JSON\n",
    "    json_data = final_df.to_json(orient=\"index\")\n",
    "    \n",
    "    # Create the filename\n",
    "    filename = os.path.join(output_directory, f\"{df_name}.json\")\n",
    "    \n",
    "    # Write JSON data to file\n",
    "    with open(filename, \"w\") as json_file:\n",
    "        json_file.write(json_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the dataframes in the dfs dictionary\n",
    "for df_name, final_df in dfs.items():\n",
    "    # Convert DataFrame to JSON\n",
    "    json_data = final_df.to_json(orient=\"index\")\n",
    "    \n",
    "    # Create the filename\n",
    "    filename = os.path.join(output_directory, f\"{df_name}.json\")\n",
    "    \n",
    "    # Write JSON data to file\n",
    "    with open(filename, \"w\") as json_file:\n",
    "        json_file.write(json_data)\n",
    "\n",
    "# convert found_categories to a json file\n",
    "my_list = list(found_categories)\n",
    "\n",
    "# Specify the output file path\n",
    "output_file_path = \"found_categories.json\"\n",
    "\n",
    "# Write the JSON data to the output file\n",
    "with open(output_file_path, \"w\") as output_file:\n",
    "    json.dump(my_list, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'df_Dishwasher':            positive  neutral  negative  popularity\n",
       " GE               10        0        40    0.000000\n",
       " MIELE            40        5         0    1.000000\n",
       " LG               40        0         5    0.937803\n",
       " BOSCH            35        0       100    0.091077\n",
       " WHIRLPOOL        45        5        10    0.850657\n",
       " SAMSUNG          10        0         5    0.473948,\n",
       " 'df_Washing Machine':             positive  neutral  negative  popularity\n",
       " GE                30       10        30    0.456860\n",
       " LG               120       15         5    0.916292\n",
       " WHIRLPOOL         50        0         0    1.000000\n",
       " MIELE             25       10         0    0.755813\n",
       " SAMSUNG           20        0        15    0.493383\n",
       " ELECTROLUX        20        5         5    0.637442\n",
       " BOSCH              0       10        35    0.000000\n",
       " SMEG               0        5         0    0.243650\n",
       " MITSUBISHI         0       10         0    0.273720\n",
       " TOWER              0        0         5    0.036246,\n",
       " 'df_Oven':             positive  neutral  negative  popularity\n",
       " SMEG              10        0         0    1.000000\n",
       " BERTAZZONI        10        0         0    1.000000\n",
       " BOSCH             10        5         5    0.712648\n",
       " ELECTROLUX        10        5         0    0.896577\n",
       " GE                 5        5        10    0.406488\n",
       " LG                 5        5         0    0.716313\n",
       " SAMSUNG            0        0        15    0.000000\n",
       " MIELE              5        5         0    0.716313\n",
       " TURBO              0        5         0    0.389599,\n",
       " 'df_Cooktop':        positive  neutral  negative  popularity\n",
       " GE            0        0         5         0.5\n",
       " BOSCH         0        0         5         0.5,\n",
       " 'df_Refrigerator':            positive  neutral  negative  popularity\n",
       " LG               35        0         0    1.000000\n",
       " GE                5        5        15    0.040270\n",
       " SAMSUNG          15        0        15    0.320610\n",
       " BOSCH             5        0        15    0.000000\n",
       " WHIRLPOOL        25        0         0    0.907681,\n",
       " 'df_Dryer':            positive  neutral  negative  popularity\n",
       " WHIRLPOOL        10        0         0    1.000000\n",
       " GE                0        0         5    0.000000\n",
       " SAMSUNG           0        0         5    0.000000\n",
       " TOSHIBA           5        0         0    0.794475\n",
       " LG               10        0         0    1.000000\n",
       " MIELE             5        0         0    0.794475\n",
       " BOSCH             0        0         5    0.000000,\n",
       " 'df_Fan':        negative  neutral  positive\n",
       " BOSCH         5        0         0,\n",
       " 'df_Griddle':     negative  neutral  positive\n",
       " LG         0        0         5,\n",
       " 'df_Heater':        positive  neutral  negative\n",
       " LG            5        0         0\n",
       " GE            0        0         5\n",
       " BOSCH         0        0        10,\n",
       " 'df_Microwave':            positive  neutral  negative\n",
       " PANASONIC         5        0         0\n",
       " BOSCH             5        0         0}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "washingmachine\n"
     ]
    }
   ],
   "source": [
    "brand = \"Washing machine\"\n",
    "\n",
    "brand = brand.replace(\" \", \"\").lower()\n",
    "print(brand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
